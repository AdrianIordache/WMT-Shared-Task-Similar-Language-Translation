{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar1_IxTi8Tb9",
        "outputId": "befd444f-0197-4bb2-a665-9209e5c15d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Master/Anul II/Sem 1/MT/Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd \"/content/drive/My Drive/Master/Anul II/Sem 1/MT/Project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JYfDE0Y93yZ"
      },
      "outputs": [],
      "source": [
        "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
        "# These will also become the suffix's of all vocab and corpus files used throughout\n",
        "import os\n",
        "source_language = \"es\"\n",
        "target_language = \"ro\" \n",
        "lc = False  # If True, lowercase the data.\n",
        "seed = 42  # Random seed for shuffling.\n",
        "tag = \"16k\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
        "\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "os.environ[\"tag\"] = tag\n",
        "\n",
        "# # This will save it to a folder in our gdrive instead!\n",
        "# !mkdir -p \"$tgt-$src-$tag\"\n",
        "# os.environ[\"gdrive_path\"] = \"%s-%s-%s\" % (target_language, source_language, tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHhoeEtD930t",
        "outputId": "47287e4f-686a-4ba6-c509-1523f27d1efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "!echo $gdrive_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iWLxP54932w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TMX file to dataframe\n",
        "source_file = 'cleaned_langid_train.{}'.format(source_language)\n",
        "target_file = 'cleaned_langid_train.{}'.format(target_language)\n",
        "\n",
        "source = []\n",
        "target = []\n",
        "\n",
        "data_dir = os.path.join('data', 'cleaned')\n",
        "\n",
        "with open(os.path.join(data_dir, source_file)) as f:\n",
        "    source.extend(f.readlines())\n",
        "with open(os.path.join(data_dir, target_file)) as f:\n",
        "    target.extend(f.readlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "peil1MN29340",
        "outputId": "89a3f273-c6ae-4af6-c612-dd28d4a0b12b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e5cb2570-d239-48fa-82e6-394d3c44e951\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Composición del Parlamento: véase el Acta\\n</td>\n",
              "      <td>Componenţa Parlamentului: a se vedea procesul-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aprobación del Acta de la sesión anterior: véa...</td>\n",
              "      <td>Aprobarea procesului-verbal al şedinţei preced...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Composición del Parlamento: véase el Acta\\n</td>\n",
              "      <td>Componenţa Parlamentului: a se vedea procesul-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5cb2570-d239-48fa-82e6-394d3c44e951')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5cb2570-d239-48fa-82e6-394d3c44e951 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5cb2570-d239-48fa-82e6-394d3c44e951');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                     source_sentence                                    target_sentence\n",
              "0        Composición del Parlamento: véase el Acta\\n  Componenţa Parlamentului: a se vedea procesul-...\n",
              "1  Aprobación del Acta de la sesión anterior: véa...  Aprobarea procesului-verbal al şedinţei preced...\n",
              "2        Composición del Parlamento: véase el Acta\\n  Componenţa Parlamentului: a se vedea procesul-..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.DataFrame(zip(source, target), columns=['source_sentence', 'target_sentence'])\n",
        "# if you get TypeError: data argument can't be an iterator is because of your zip version run this below\n",
        "#df = pd.DataFrame(list(zip(source, target)), columns=['source_sentence', 'target_sentence'])\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjAJLgKICAOv",
        "outputId": "a648d317-bb88-4ce3-bf27-520103c86c02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "846253"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9duWehb936w",
        "outputId": "945d8271-a225-431f-e2a1-d87efc872198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# drop duplicate translations\n",
        "df_pp = df.drop_duplicates()\n",
        "\n",
        "# drop conflicting translations\n",
        "# (this is optional and something that you might want to comment out \n",
        "# depending on the size of your corpus)\n",
        "df_pp.drop_duplicates(subset='source_sentence', inplace=True)\n",
        "df_pp.drop_duplicates(subset='target_sentence', inplace=True)\n",
        "\n",
        "# Shuffle the data to remove bias in dev set selection.\n",
        "df_pp = df_pp.sample(frac=1, random_state=seed).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRZLBZq-B-5P",
        "outputId": "4f24c795-226b-4e8c-f426-882b45bf9417"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "710198"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(df_pp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejxf1FjgBsRp"
      },
      "outputs": [],
      "source": [
        "# # Install fuzzy wuzzy to remove \"almost duplicate\" sentences in the\n",
        "# # test and training sets.\n",
        "# ! pip install fuzzywuzzy\n",
        "# ! pip install python-Levenshtein\n",
        "# import time\n",
        "# from fuzzywuzzy import process\n",
        "# import numpy as np\n",
        "# from os import cpu_count\n",
        "# from functools import partial\n",
        "# from multiprocessing import Pool\n",
        "\n",
        "\n",
        "# # reset the index of the training set after previous filtering\n",
        "# df_pp.reset_index(drop=False, inplace=True)\n",
        "\n",
        "# # Remove samples from the training data set if they \"almost overlap\" with the\n",
        "# # samples in the test set.\n",
        "\n",
        "# # Filtering function. Adjust pad to narrow down the candidate matches to\n",
        "# # within a certain length of characters of the given sample.\n",
        "# def fuzzfilter(sample, candidates, pad):\n",
        "#   candidates = [x for x in candidates if len(x) <= len(sample)+pad and len(x) >= len(sample)-pad] \n",
        "#   if len(candidates) > 0:\n",
        "#     return process.extractOne(sample, candidates)[1]\n",
        "#   else:\n",
        "#     return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5uBonUuBsUD"
      },
      "outputs": [],
      "source": [
        "# start_time = time.time()\n",
        "# ### iterating over pandas dataframe rows is not recomended, let use multi processing to apply the function\n",
        "\n",
        "# with Pool(cpu_count()-1) as pool:\n",
        "#     scores = pool.map(partial(fuzzfilter, candidates=list(en_test_sents), pad=5), df_pp['source_sentence'])\n",
        "# hours, rem = divmod(time.time() - start_time, 3600)\n",
        "# minutes, seconds = divmod(rem, 60)\n",
        "# print(\"done in {}h:{}min:{}seconds\".format(hours, minutes, seconds))\n",
        "\n",
        "# # Filter out \"almost overlapping samples\"\n",
        "# df_pp = df_pp.assign(scores=scores)\n",
        "# df_pp = df_pp[df_pp['scores'] < 95]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57KmftRB1PJZ"
      },
      "outputs": [],
      "source": [
        "data_folder = os.path.join('data', '{}-{}-{}'.format(source_language, target_language, tag))\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "phase = 'train'\n",
        "\n",
        "with open(os.path.join(data_folder, '{}.{}'.format(phase, source_language)), \"w\") as src_file, open(os.path.join(data_folder, '{}.{}'.format(phase, target_language)), \"w\") as trg_file:\n",
        "    for index, row in df_pp.iterrows():\n",
        "        src_file.write(row[\"source_sentence\"])\n",
        "        trg_file.write(row[\"target_sentence\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ca1SsduBsXe",
        "outputId": "3104c422-ff07-48cc-8520-ef989bc12cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> data/es-ro-16k/train.es <==\n",
            "También aceptamos que las medidas y sanciones específicas tienen por objeto minimizar el impacto sobre la población civil y me complace que haya mencionado precisamente esta cláusula, señora Malström.\n",
            "Los inspectores de la Comisión ejercerán sus facultades previa presentación de una habilitación escrita en la que se indicarán su identidad y la calidad en la que concurren, acompañada de un documento en que se indique el objeto y la finalidad del control y verificación in situ.\n",
            "Si se reprimen los derechos humanos, con independencia de dónde se repriman, no podemos nunca transigir.\n",
            "a) obtener información de cualquier pedido u operación relativo a las sustancias catalogadas;\n",
            "Debemos proponer oportunidades favorables en materia de planificación fiscal.\n",
            "- 25,72 euros por 100 kilogramos a partir del 1 de julio de 2007.\n",
            "(DE) Señor Presidente, el día que celebramos el 60º aniversario del plan Schuman, el 9 de mayo de 2010, el Consejo enterró formalmente el método Monnet, con la ayuda de la Comisión.\n",
            "He apoyado la propuesta de resolución común, que invita a todos los Estados miembros a que ratifiquen esta Convención para permitir así la adhesión de la Unión a la misma.\n",
            "\"1. Para la realización de las acciones que formen parte de los programas contemplados en el artículo 7 del Reglamento (CE) n° 2702/1999, el Estado miembro interesado recibirá, tras realizar su convocatoria de propuestas, cada año, a más tardar el 30 de abril y el 31 de octubre, los programas de los organizaciones profesionales o interprofesionales de la Comunidad representativas del sector o sectores afectados.\n",
            "Con respecto al futuro, la cuestión clave mencionada por alguien es: ¿qué pasa en Indonesia, qué pasa en los Estados Unidos?\n",
            "\n",
            "==> data/es-ro-16k/train.ro <==\n",
            "Acceptăm, de asemenea, ca măsurile şi sancţiunile vizate să aibă drept obiectiv reducerea impactul asupra populaţiei civile şi sunt bucuroasă că aţi menţionat această clauză în mod specific, dnă Malmström.\n",
            "Inspectorii Comisiei îşi exercită atribuţiile în baza unei autorizaţii scrise care le atestă identitatea şi poziţia, împreună cu un document care indică obiectul şi scopul controlului sau inspecţiei la faţa locului.\n",
            "Atunci când drepturile omului sunt reprimate, indiferent de locul în care are loc acest lucru, nu putem face absolut niciun compromis.\n",
            "(a) să obţină informaţii referitoare la oricare comenzi sau operaţiuni care implică substanţele menţionate în listă;\n",
            "Trebuie să propunem oportunități fiscale favorabile.\n",
            "- 25,72 începând de la 1 iulie 2007.\n",
            "(DE) Dle preşedinte, în ziua în care am sărbătorit cea de-a 60-a aniversare a Planului Schuman, la 9 mai 2010, Consiliul a renunţat în mod oficial la metoda Monnet, cu ajutorul Comisiei.\n",
            "Am susţinut rezoluţia comună, care invită toate statele membre să ratifice Convenţia, permiţând astfel aderarea Uniunii la aceasta din urmă.\n",
            "\"(1) În vederea realizării acţiunilor care fac parte din programele prevăzute în articolul 7 din Regulamentul (CE) 2702/1999, statul membru în cauză primeşte anual, ca urmare a solicitării sale de propuneri, până la 30 aprilie şi, respectiv, 31 octombrie, programe ale organizaţiilor profesionale sau interprofesionale din Comunitate, reprezentative pentru sectorul sau sectoarele în cauză.\n",
            "În ceea ce priveşte viitorul, subiectul cheie menţionat de cineva a fost: cum rămâne cu Indonezia, cum rămâne cu Statele Unite?\n",
            "==> data/es-ro-16k/dev.es <==\n",
            "El propósito del Fondo de Solidaridad de la Unión Europea («el Fondo») es que la Unión pueda responder de manera rápida, eficiente y flexible a las situaciones de emergencia con el fin de solidarizarse con la población de las regiones afectadas por catástrofes naturales.\n",
            "El importe anual máximo del Fondo no excederá de 500000000 EUR (a precios de 2011), conforme a lo dispuesto en el artículo 10 del Reglamento (UE, Euratom) n.o 1311/2013 del Consejo.\n",
            "El 11 de enero de 2018, Bulgaria presentó una solicitud de movilización del Fondo a raíz de las inundaciones provocadas por las intensas precipitaciones y las violentas tormentas de los días 25 y 26 de octubre de 2017.\n",
            "El 11 de octubre de 2017, Grecia presentó una solicitud de movilización del Fondo a raíz de un seísmo que afectó a la región del Egeo Meridional y a la isla de Kos el 20 de julio de 2017.\n",
            "El 22 de diciembre de 2017, Lituania presentó una solicitud de movilización del Fondo a raíz de las inundaciones provocadas por las continuas lluvias del verano y el otoño de 2017.\n",
            "El 25 de octubre de 2017, Polonia presentó una solicitud de movilización del Fondo a raíz de las tormentas excepcionalmente violentas y las intensas lluvias registradas entre los días 9 y 12 de agosto de 2017.\n",
            "Las solicitudes de Bulgaria, Grecia, Lituania y Polonia cumplen las condiciones para recibir una contribución financiera del Fondo con arreglo al artículo 4 del Reglamento (CE) n.o 2012/2002.\n",
            "Por consiguiente, el Fondo debe movilizarse para aportar una contribución financiera en favor de Bulgaria, Grecia, Lituania y Polonia.\n",
            "Con el fin de reducir al mínimo el tiempo necesario para movilizar el Fondo, la presente Decisión debe aplicarse a partir de la fecha de su adopción,\n",
            "HAN ADOPTADO LA PRESENTE DECISIÓN:\n",
            "\n",
            "==> data/es-ro-16k/dev.ro-es.ro <==\n",
            "Obiectivul Fondului de solidaritate al Uniunii Europene („fondul”) este de a-i permite Uniunii să răspundă într-un mod rapid, eficient și flexibil situațiilor de urgență pentru a-și exprima solidaritatea față de populația din regiunile afectate de catastrofe naturale.\n",
            "Fondul nu depășește o valoare anuală maximă de 500000000 EUR (la prețurile din 2011), astfel cum se prevede la articolul 10 din Regulamentul (UE, Euratom) nr. 1311/2013 al Consiliului.\n",
            "La 11 ianuarie 2018, Bulgaria a prezentat o cerere de mobilizare a fondului, în urma inundațiilor provocate de precipitațiile abundente și de furtunile violente care au avut loc în perioada 25-26 octombrie 2017.\n",
            "La 11 octombrie 2017, Grecia a prezentat o cerere de mobilizare a fondului, în urma cutremurului din 20 iulie 2017 care a afectat regiunea Egeea de Sud și insula Kos.\n",
            "La 22 decembrie 2017, Lituania a prezentat o cerere de mobilizare a fondului, în urma inundațiilor provocate de precipitațiile neîntrerupte care au căzut în cursul verii și toamnei anului 2017.\n",
            "La 25 octombrie 2017, Polonia a prezentat o cerere de mobilizare a fondului, în urma furtunilor extrem de violente și a precipitațiilor abundente înregistrate în perioada 9-12 august 2017.\n",
            "Cererile prezentate de Bulgaria, Grecia, Lituania și Polonia îndeplinesc condițiile de acordare a unei contribuții financiare din fond, astfel cum se prevede la articolul 4 din Regulamentul (CE) nr. 2012/2002.\n",
            "Prin urmare, fondul ar trebui să fie mobilizat pentru a se acorda o contribuție financiară Bulgariei, Greciei, Lituaniei și Poloniei.\n",
            "Pentru a se reduce la minimum perioada necesară pentru mobilizarea fondului, prezenta decizie ar trebui să se aplice de la data adoptării,\n",
            "ADOPTĂ PREZENTA DECIZIE:\n"
          ]
        }
      ],
      "source": [
        "# Doublecheck the format below. There should be no extra quotation marks or weird characters.\n",
        "! head data/$src-$tgt-$tag/train.*\n",
        "! head data/$src-$tgt-$tag/dev.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RAcQz351CxeR",
        "outputId": "31b534d0-8dab-403b-a8c7-fbf235b89413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting joeynmt\n",
            "  Downloading joeynmt-1.3-py3-none-any.whl (84 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▉                            | 10 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 20 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 84 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from joeynmt) (7.1.2)\n",
            "Collecting wrapt==1.11.1\n",
            "  Downloading wrapt-1.11.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from joeynmt) (0.11.2)\n",
            "Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.7/dist-packages (from joeynmt) (2.7.0)\n",
            "Collecting six==1.12\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting subword-nmt\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl (27 kB)\n",
            "Collecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from joeynmt) (0.16.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.7 MB/s \n",
            "\u001b[?25hCollecting pylint\n",
            "  Downloading pylint-2.12.2-py3-none-any.whl (414 kB)\n",
            "\u001b[K     |████████████████████████████████| 414 kB 58.6 MB/s \n",
            "\u001b[?25hCollecting numpy==1.20.1\n",
            "  Downloading numpy-1.20.1-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 2.8 MB/s \n",
            "\u001b[?25hCollecting sacrebleu>=1.3.6\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from joeynmt) (3.2.2)\n",
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from joeynmt) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->joeynmt) (3.10.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0->joeynmt) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0->joeynmt) (4.62.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.3.6->joeynmt) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.3.6->joeynmt) (2019.12.20)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (0.12.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (1.43.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.15->joeynmt) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->joeynmt) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->joeynmt) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->joeynmt) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.15->joeynmt) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.15->joeynmt) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15->joeynmt) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0->joeynmt) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0->joeynmt) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0->joeynmt) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0->joeynmt) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15->joeynmt) (3.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joeynmt) (2.8.2)\n",
            "Requirement already satisfied: toml>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from pylint->joeynmt) (0.10.2)\n",
            "Collecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
            "Collecting astroid<2.10,>=2.9.0\n",
            "  Downloading astroid-2.9.3-py3-none-any.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 65.6 MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting isort<6,>=4.2.5\n",
            "  Downloading isort-5.10.1-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 69.2 MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy>=1.4.0\n",
            "  Downloading lazy_object_proxy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting typed-ast<2.0,>=1.4.0\n",
            "  Downloading typed_ast-1.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn->joeynmt) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn->joeynmt) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn->joeynmt) (2018.9)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.11.1-cp37-cp37m-linux_x86_64.whl size=68431 sha256=22bef606510272a3d96d979ac7e3797ea106731c5f05af94bf80c4ae3ac6769b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/58/9d/da8bad4545585ca52311498ff677647c95c7b690b3040171f8\n",
            "Successfully built wrapt\n",
            "Installing collected packages: six, wrapt, typed-ast, numpy, lazy-object-proxy, torch, portalocker, platformdirs, mock, mccabe, isort, colorama, astroid, torchtext, subword-nmt, sacrebleu, pyyaml, pylint, joeynmt\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.20.1 which is incompatible.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-python-client 1.12.8 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-core 1.26.3 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed astroid-2.9.3 colorama-0.4.4 isort-5.10.1 joeynmt-1.3 lazy-object-proxy-1.7.1 mccabe-0.6.1 mock-4.0.3 numpy-1.20.1 platformdirs-2.4.1 portalocker-2.3.2 pylint-2.12.2 pyyaml-6.0 sacrebleu-2.0.0 six-1.12.0 subword-nmt-0.3.8 torch-1.8.0 torchtext-0.9.0 typed-ast-1.5.1 wrapt-1.11.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install joeynmt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U605STWyCxsM",
        "outputId": "0405db9e-24f5-4300-bf3a-8c5288db0a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 16000/16000 [02:06<00:00, 126.06it/s]\n"
          ]
        }
      ],
      "source": [
        "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \n",
        "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\n",
        "\n",
        "# Learn BPEs on the training data.\n",
        "# os.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\",target_language + source_language ) # Herman! \n",
        "! subword-nmt learn-joint-bpe-and-vocab --input data/$src-$tgt-$tag/train.$src data/$src-$tgt-$tag/train.$tgt -s 16000 -o data/$src-$tgt-$tag/bpe.codes.16000 --write-vocabulary data/$src-$tgt-$tag/vocab.$src data/$src-$tgt-$tag/vocab.$tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOwrskJjCxwF"
      },
      "outputs": [],
      "source": [
        "# Apply BPE splits to the development and test data.\n",
        "! subword-nmt apply-bpe -c data/$src-$tgt-$tag/bpe.codes.16000 --vocabulary data/$src-$tgt-$tag/vocab.$src < data/$src-$tgt-$tag/train.$src > data/$src-$tgt-$tag/train.bpe.$src\n",
        "! subword-nmt apply-bpe -c data/$src-$tgt-$tag/bpe.codes.16000 --vocabulary data/$src-$tgt-$tag/vocab.$tgt < data/$src-$tgt-$tag/train.$tgt > data/$src-$tgt-$tag/train.bpe.$tgt\n",
        "\n",
        "! subword-nmt apply-bpe -c data/$src-$tgt-$tag/bpe.codes.16000 --vocabulary data/$src-$tgt-$tag/vocab.$src < data/$src-$tgt-$tag/dev.$src > data/$src-$tgt-$tag/dev.bpe.$src\n",
        "! subword-nmt apply-bpe -c data/$src-$tgt-$tag/bpe.codes.16000 --vocabulary data/$src-$tgt-$tag/vocab.$tgt < data/$src-$tgt-$tag/dev.$tgt > data/$src-$tgt-$tag/dev.bpe.$tgt\n",
        "! subword-nmt apply-bpe -c data/$src-$tgt-$tag/bpe.codes.16000 --vocabulary data/$src-$tgt-$tag/vocab.$src < data/$src-$tgt-$tag/test.$src > data/$src-$tgt-$tag/test.bpe.$src\n",
        "! subword-nmt apply-bpe -c data/$src-$tgt-$tag/bpe.codes.16000 --vocabulary data/$src-$tgt-$tag/vocab.$tgt < data/$src-$tgt-$tag/test.$tgt > data/$src-$tgt-$tag/test.bpe.$tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyynGBuyCxyg",
        "outputId": "3dcd6366-933c-4503-9374-47cd4826fc69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'joeynmt'...\n",
            "remote: Enumerating objects: 3229, done.\u001b[K\n",
            "remote: Counting objects: 100% (278/278), done.\u001b[K\n",
            "remote: Compressing objects: 100% (146/146), done.\u001b[K\n",
            "remote: Total 3229 (delta 157), reused 212 (delta 132), pack-reused 2951\u001b[K\n",
            "Receiving objects: 100% (3229/3229), 8.19 MiB | 6.37 MiB/s, done.\n",
            "Resolving deltas: 100% (2186/2186), done.\n",
            "Checking out files: 100% (119/119), done.\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/joeynmt/joeynmt.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t89sTYO2Cx05",
        "outputId": "623db070-2494-46d3-c2bc-b715fc9037eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BPE Romanian Sentences\n",
            "Co@@ eren@@ ța și complement@@ ar@@ itatea Cor@@ p@@ ului european de solidaritate ar trebui să fie asigur@@ ate alături de alte politici și programe relevante ale Uniunii.\n",
            "Sprij@@ inul acordat în cadrul programului ar trebui să fie furnizat de către Comisie la cererea unui stat membru, în domenii legate de coezi@@ une, competitiv@@ itate, productiv@@ itate, inov@@ are, creșterea intelig@@ entă, durabilă și favor@@ abilă incluzi@@ uni@@ i, locurile de muncă și investi@@ ții, precum bugetul și fiscal@@ itatea, administr@@ ația publică, reformele institu@@ ționale și administr@@ ative, sistemele de justi@@ ție, combaterea frau@@ de@@ i, a corup@@ ți@@ ei, a sp@@ ăl@@ ării b@@ anilor și a ev@@ azi@@ unii fiscal@@ e, mediul de afac@@ eri, dezvoltarea sectorului priv@@ at, concuren@@ ț@@ a, achizi@@ țiile publice, participarea publică în întreprinderi, proce@@ sele de priv@@ atiz@@ are, accesul la finanț@@ are, politicile din sectorul financiar, comerț@@ ul, dezvoltarea dur@@ abilă, educ@@ ația și form@@ area, politicile în materie de ocupare a forței de muncă, sănătatea publică, azil@@ ul, politicile privind migr@@ ați@@ a, agricultura, dezvoltarea rurală și pescuit@@ ul.\n",
            "Euro@@ fo@@ un@@ d furnizează instituțiilor și organ@@ elor Uniunii, statelor membre și parten@@ erilor soci@@ ali informații speci@@ alizate și cu valoare adăugată în domeniul de competen@@ ță al Euro@@ fo@@ un@@ d.\n",
            "Acesta prevede că egalitatea între femei și bărb@@ ați trebuie asigurată în toate domeni@@ ile, inclusiv în ceea ce privește încad@@ r@@ area în muncă, munca și remuner@@ area.\n",
            "Consiliul EF@@ RA@@ G, care reflectă o reprezent@@ are echilibr@@ ată a intereselor publice și priv@@ ate, ar trebui să se asigure că membrii săi se angajează să acțion@@ eze în interesul public european.Combined BPE Vocab\n",
            "ì\n",
            "î.H@@\n",
            "…\n",
            "δ\n",
            "⅓@@\n",
            "ż\n",
            "Ґ\n",
            "@@\n",
            "@@\n",
            "îndepl@@\n"
          ]
        }
      ],
      "source": [
        "# Create that vocab using build_vocab\n",
        "! sudo chmod 777 joeynmt/scripts/build_vocab.py\n",
        "! joeynmt/scripts/build_vocab.py data/$src-$tgt-$tag/train.bpe.$src data/$src-$tgt-$tag/train.bpe.$tgt --output_path data/$src-$tgt-$tag/vocab.txt\n",
        "\n",
        "# Some output\n",
        "! echo \"BPE Romanian Sentences\"\n",
        "! tail -n 5 data/$src-$tgt-$tag/test.bpe.$tgt\n",
        "! echo \"Combined BPE Vocab\"\n",
        "! tail -n 10 data/$src-$tgt-$tag/vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCtQm--fCx2p"
      },
      "outputs": [],
      "source": [
        "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
        "# (You can of course play with all the parameters if you'd like!)\n",
        "\n",
        "name = '{}-{}-{}'.format(source_language, target_language, tag)\n",
        "\n",
        "# Create the config\n",
        "config = \"\"\"\n",
        "name: \"{source_language}-{target_language}-{tag}_transformer\"\n",
        "\n",
        "data:\n",
        "    src: \"{source_language}\"\n",
        "    trg: \"{target_language}\"\n",
        "    train: \"data/{name}/train.bpe\"\n",
        "    dev:   \"data/{name}/dev.bpe\"\n",
        "    test:  \"data/{name}/test.bpe\"\n",
        "    level: \"bpe\"\n",
        "    lowercase: False\n",
        "    max_sent_length: 256\n",
        "    src_vocab: \"data/{name}/vocab.txt\"\n",
        "    trg_vocab: \"data/{name}/vocab.txt\"\n",
        "\n",
        "testing:\n",
        "    beam_size: 4\n",
        "    alpha: 1.0\n",
        "\n",
        "training:\n",
        "    #load_model: \"models/{name}_transformer/1.ckpt\" # if uncommented, load a pre-trained model from this checkpoint\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.999] \n",
        "    scheduling: \"plateau\"           # TODO: try switching from plateau to Noam scheduling\n",
        "    patience: 5                     # For plateau: decrease learning rate by decrease_factor if validation score has not improved for this many validation rounds.\n",
        "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
        "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
        "    decrease_factor: 0.7\n",
        "    loss: \"crossentropy\"\n",
        "    learning_rate: 0.0003\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.1\n",
        "    batch_size: 4096\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 3600\n",
        "    eval_batch_type: \"token\"\n",
        "    batch_multiplier: 1\n",
        "    early_stopping_metric: \"ppl\"\n",
        "    epochs: 10                  # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
        "    validation_freq: 1000          # TODO: Set to at least once per epoch.\n",
        "    logging_freq: 100\n",
        "    eval_metric: \"bleu\"\n",
        "    model_dir: \"models/{name}_transformer\"\n",
        "    overwrite: True              # TODO: Set to True if you want to overwrite possibly existing models. \n",
        "    shuffle: True\n",
        "    use_cuda: True\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_last_ckpts: 3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 16             # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 1024   # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 1024        # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 4096            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 16              # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 1024    # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 1024        # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 4096            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "\"\"\".format(name=name, source_language=source_language, target_language=target_language, tag=tag)\n",
        "with open(\"configs/transformer_{name}.yaml\".format(name=name),'w') as f:\n",
        "    f.write(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR7w2DLwMviE",
        "outputId": "21c0a55f-4d14-4073-b6a3-07f8f0f8213b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-16 17:31:08,243 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
            "2022-01-16 17:31:08,286 - INFO - joeynmt.data - Loading training data...\n",
            "2022-01-16 17:31:27,650 - INFO - joeynmt.data - Building vocabulary...\n",
            "2022-01-16 17:31:32,198 - INFO - joeynmt.data - Loading dev data...\n",
            "2022-01-16 17:31:32,327 - INFO - joeynmt.data - Loading test data...\n",
            "2022-01-16 17:31:32,348 - INFO - joeynmt.data - Data loaded.\n",
            "2022-01-16 17:31:32,348 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2022-01-16 17:31:35,392 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2022-01-16 17:31:37,653 - INFO - joeynmt.training - Total params: 193345536\n",
            "2022-01-16 17:31:41,664 - INFO - joeynmt.helpers - cfg.name                           : es-ro-16k_transformer\n",
            "2022-01-16 17:31:41,665 - INFO - joeynmt.helpers - cfg.data.src                       : es\n",
            "2022-01-16 17:31:41,665 - INFO - joeynmt.helpers - cfg.data.trg                       : ro\n",
            "2022-01-16 17:31:41,665 - INFO - joeynmt.helpers - cfg.data.train                     : data/es-ro-16k/train.bpe\n",
            "2022-01-16 17:31:41,665 - INFO - joeynmt.helpers - cfg.data.dev                       : data/es-ro-16k/dev.bpe\n",
            "2022-01-16 17:31:41,665 - INFO - joeynmt.helpers - cfg.data.test                      : data/es-ro-16k/test.bpe\n",
            "2022-01-16 17:31:41,666 - INFO - joeynmt.helpers - cfg.data.level                     : bpe\n",
            "2022-01-16 17:31:41,666 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False\n",
            "2022-01-16 17:31:41,666 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 256\n",
            "2022-01-16 17:31:41,666 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : data/es-ro-16k/vocab.txt\n",
            "2022-01-16 17:31:41,666 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : data/es-ro-16k/vocab.txt\n",
            "2022-01-16 17:31:41,666 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 4\n",
            "2022-01-16 17:31:41,667 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0\n",
            "2022-01-16 17:31:41,667 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42\n",
            "2022-01-16 17:31:41,667 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam\n",
            "2022-01-16 17:31:41,667 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens\n",
            "2022-01-16 17:31:41,667 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2022-01-16 17:31:41,667 - INFO - joeynmt.helpers - cfg.training.scheduling            : plateau\n",
            "2022-01-16 17:31:41,667 - INFO - joeynmt.helpers - cfg.training.patience              : 5\n",
            "2022-01-16 17:31:41,668 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 0.5\n",
            "2022-01-16 17:31:41,668 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 1000\n",
            "2022-01-16 17:31:41,668 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7\n",
            "2022-01-16 17:31:41,668 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy\n",
            "2022-01-16 17:31:41,668 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0003\n",
            "2022-01-16 17:31:41,668 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08\n",
            "2022-01-16 17:31:41,668 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0\n",
            "2022-01-16 17:31:41,669 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1\n",
            "2022-01-16 17:31:41,669 - INFO - joeynmt.helpers - cfg.training.batch_size            : 4096\n",
            "2022-01-16 17:31:41,669 - INFO - joeynmt.helpers - cfg.training.batch_type            : token\n",
            "2022-01-16 17:31:41,669 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 3600\n",
            "2022-01-16 17:31:41,669 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token\n",
            "2022-01-16 17:31:41,669 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1\n",
            "2022-01-16 17:31:41,669 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl\n",
            "2022-01-16 17:31:41,670 - INFO - joeynmt.helpers - cfg.training.epochs                : 10\n",
            "2022-01-16 17:31:41,670 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 1000\n",
            "2022-01-16 17:31:41,670 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100\n",
            "2022-01-16 17:31:41,670 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu\n",
            "2022-01-16 17:31:41,670 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/es-ro-16k_transformer\n",
            "2022-01-16 17:31:41,670 - INFO - joeynmt.helpers - cfg.training.overwrite             : True\n",
            "2022-01-16 17:31:41,671 - INFO - joeynmt.helpers - cfg.training.shuffle               : True\n",
            "2022-01-16 17:31:41,671 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True\n",
            "2022-01-16 17:31:41,671 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100\n",
            "2022-01-16 17:31:41,671 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
            "2022-01-16 17:31:41,671 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3\n",
            "2022-01-16 17:31:41,671 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier\n",
            "2022-01-16 17:31:41,671 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros\n",
            "2022-01-16 17:31:41,672 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0\n",
            "2022-01-16 17:31:41,672 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier\n",
            "2022-01-16 17:31:41,672 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0\n",
            "2022-01-16 17:31:41,672 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : True\n",
            "2022-01-16 17:31:41,672 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True\n",
            "2022-01-16 17:31:41,672 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer\n",
            "2022-01-16 17:31:41,673 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6\n",
            "2022-01-16 17:31:41,673 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 16\n",
            "2022-01-16 17:31:41,673 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 1024\n",
            "2022-01-16 17:31:41,673 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True\n",
            "2022-01-16 17:31:41,673 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.2\n",
            "2022-01-16 17:31:41,673 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 1024\n",
            "2022-01-16 17:31:41,673 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 4096\n",
            "2022-01-16 17:31:41,674 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.3\n",
            "2022-01-16 17:31:41,674 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer\n",
            "2022-01-16 17:31:41,674 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6\n",
            "2022-01-16 17:31:41,674 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 16\n",
            "2022-01-16 17:31:41,674 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 1024\n",
            "2022-01-16 17:31:41,674 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True\n",
            "2022-01-16 17:31:41,674 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.2\n",
            "2022-01-16 17:31:41,675 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 1024\n",
            "2022-01-16 17:31:41,675 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 4096\n",
            "2022-01-16 17:31:41,675 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.3\n",
            "2022-01-16 17:31:41,675 - INFO - joeynmt.helpers - Data set sizes: \n",
            "\ttrain 710017,\n",
            "\tvalid 970,\n",
            "\ttest 1000\n",
            "2022-01-16 17:31:41,675 - INFO - joeynmt.helpers - First training example:\n",
            "\t[SRC] También acept@@ amos que las medidas y sanciones específicas tienen por objeto mini@@ mi@@ zar el impacto sobre la población civil y me complace que haya mencionado precisamente esta cláus@@ ul@@ a, señora Mal@@ strö@@ m.\n",
            "\t[TRG] Ac@@ cep@@ tă@@ m, de asemenea, ca măsurile şi sanc@@ ţiunile vizate să aibă drept obiectiv reducerea impactul asupra populaţiei civile şi sunt bucu@@ ro@@ asă că aţi menţionat această clau@@ ză în mod specific@@ , dnă Malmströ@@ m.\n",
            "2022-01-16 17:31:41,675 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) la (6) a (7) în (8) en (9) que\n",
            "2022-01-16 17:31:41,676 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) la (6) a (7) în (8) en (9) que\n",
            "2022-01-16 17:31:41,676 - INFO - joeynmt.helpers - Number of Src words (types): 16586\n",
            "2022-01-16 17:31:41,677 - INFO - joeynmt.helpers - Number of Trg words (types): 16586\n",
            "2022-01-16 17:31:41,677 - INFO - joeynmt.training - Model(\n",
            "\tencoder=TransformerEncoder(num_layers=6, num_heads=16),\n",
            "\tdecoder=TransformerDecoder(num_layers=6, num_heads=16),\n",
            "\tsrc_embed=Embeddings(embedding_dim=1024, vocab_size=16586),\n",
            "\ttrg_embed=Embeddings(embedding_dim=1024, vocab_size=16586))\n",
            "2022-01-16 17:31:41,702 - INFO - joeynmt.training - Train stats:\n",
            "\tdevice: cuda\n",
            "\tn_gpu: 1\n",
            "\t16-bits training: False\n",
            "\tgradient accumulation: 1\n",
            "\tbatch size per device: 4096\n",
            "\ttotal batch size (w. parallel & accumulation): 4096\n",
            "2022-01-16 17:31:41,702 - INFO - joeynmt.training - EPOCH 1\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/__main__.py\", line 48, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/__main__.py\", line 35, in main\n",
            "    train(cfg_file=args.config_path, skip_test=args.skip_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/training.py\", line 804, in train\n",
            "    trainer.train_and_validate(train_data=train_data, valid_data=dev_data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/training.py\", line 427, in train_and_validate\n",
            "    batch_loss += self._train_step(batch)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/training.py\", line 506, in _train_step\n",
            "    batch_loss, _, _, _ = self.model(return_type=\"loss\", **vars(batch))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/model.py\", line 85, in forward\n",
            "    out, _, _, _ = self._encode_decode(**kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/model.py\", line 129, in _encode_decode\n",
            "    **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/model.py\", line 150, in _encode\n",
            "    **_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/encoders.py\", line 222, in forward\n",
            "    x = layer(x, mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/transformer_layers.py\", line 203, in forward\n",
            "    h = self.src_src_att(x_norm, x_norm, x_norm, mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joeynmt/transformer_layers.py\", line 55, in forward\n",
            "    k = self.k_layer(k)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 94, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1753, in linear\n",
            "    return torch._C._nn.linear(input, weight, bias)\n",
            "RuntimeError: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasCreate(handle)`\n"
          ]
        }
      ],
      "source": [
        "!python3 -m joeynmt train configs/transformer_$src-$tgt-$tag.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uPuYSGI1PJf",
        "outputId": "95637c0e-f99c-404e-dbd0-c0a5a4b4b213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Steps: 1000\tLoss: 239859.79688\tPPL: 417.78537\tbleu: 0.27107\tLR: 0.00030000\t*\r\n",
            "Steps: 2000\tLoss: 216262.40625\tPPL: 230.73006\tbleu: 0.64724\tLR: 0.00030000\t*\r\n",
            "Steps: 3000\tLoss: 201893.92188\tPPL: 160.73090\tbleu: 1.42068\tLR: 0.00030000\t*\r\n",
            "Steps: 4000\tLoss: 188481.70312\tPPL: 114.69482\tbleu: 2.07439\tLR: 0.00030000\t*\r\n",
            "Steps: 5000\tLoss: 178688.35938\tPPL: 89.64613\tbleu: 3.33894\tLR: 0.00030000\t*\r\n",
            "Steps: 6000\tLoss: 168644.85938\tPPL: 69.62834\tbleu: 4.36631\tLR: 0.00030000\t*\r\n",
            "Steps: 7000\tLoss: 160015.06250\tPPL: 56.03870\tbleu: 5.16159\tLR: 0.00030000\t*\r\n",
            "Steps: 8000\tLoss: 150302.75000\tPPL: 43.88958\tbleu: 6.85876\tLR: 0.00030000\t*\r\n",
            "Steps: 9000\tLoss: 142119.10938\tPPL: 35.72223\tbleu: 9.15991\tLR: 0.00030000\t*\r\n",
            "Steps: 10000\tLoss: 132136.56250\tPPL: 27.78812\tbleu: 9.86780\tLR: 0.00030000\t*\r\n",
            "Steps: 11000\tLoss: 124056.19531\tPPL: 22.67591\tbleu: 12.55624\tLR: 0.00030000\t*\r\n",
            "Steps: 12000\tLoss: 117882.40625\tPPL: 19.41349\tbleu: 14.65970\tLR: 0.00030000\t*\r\n",
            "Steps: 13000\tLoss: 112325.68750\tPPL: 16.88050\tbleu: 16.00705\tLR: 0.00030000\t*\r\n",
            "Steps: 14000\tLoss: 108857.24219\tPPL: 15.46983\tbleu: 16.80927\tLR: 0.00030000\t*\r\n",
            "Steps: 15000\tLoss: 106264.35156\tPPL: 14.49282\tbleu: 17.28429\tLR: 0.00030000\t*\r\n",
            "Steps: 16000\tLoss: 103715.51562\tPPL: 13.59257\tbleu: 17.83923\tLR: 0.00030000\t*\r\n",
            "Steps: 17000\tLoss: 102942.22656\tPPL: 13.33067\tbleu: 18.20073\tLR: 0.00030000\t*\r\n",
            "Steps: 18000\tLoss: 97782.46875\tPPL: 11.70769\tbleu: 20.00361\tLR: 0.00030000\t*\r\n",
            "Steps: 19000\tLoss: 94971.42969\tPPL: 10.90825\tbleu: 20.62441\tLR: 0.00030000\t*\r\n",
            "Steps: 20000\tLoss: 93919.44531\tPPL: 10.62331\tbleu: 20.86243\tLR: 0.00030000\t*\r\n",
            "Steps: 21000\tLoss: 92466.11719\tPPL: 10.24187\tbleu: 21.01867\tLR: 0.00030000\t*\r\n",
            "Steps: 22000\tLoss: 90739.78906\tPPL: 9.80654\tbleu: 21.70514\tLR: 0.00030000\t*\r\n",
            "Steps: 23000\tLoss: 90895.76562\tPPL: 9.84510\tbleu: 21.41931\tLR: 0.00030000\t\r\n",
            "Steps: 24000\tLoss: 89097.63281\tPPL: 9.40961\tbleu: 21.91043\tLR: 0.00030000\t*\r\n",
            "Steps: 25000\tLoss: 87438.18750\tPPL: 9.02483\tbleu: 23.05094\tLR: 0.00030000\t*\r\n",
            "Steps: 26000\tLoss: 86341.84375\tPPL: 8.77929\tbleu: 23.04227\tLR: 0.00030000\t*\r\n",
            "Steps: 27000\tLoss: 85436.64844\tPPL: 8.58160\tbleu: 23.79280\tLR: 0.00030000\t*\r\n",
            "Steps: 28000\tLoss: 85200.03906\tPPL: 8.53066\tbleu: 23.59975\tLR: 0.00030000\t*\r\n",
            "Steps: 29000\tLoss: 83595.78125\tPPL: 8.19319\tbleu: 24.14012\tLR: 0.00030000\t*\r\n",
            "Steps: 30000\tLoss: 83812.40625\tPPL: 8.23797\tbleu: 24.40220\tLR: 0.00030000\t\r\n",
            "Steps: 31000\tLoss: 83092.17969\tPPL: 8.09003\tbleu: 24.00210\tLR: 0.00030000\t*\r\n",
            "Steps: 32000\tLoss: 81789.82031\tPPL: 7.82923\tbleu: 24.54050\tLR: 0.00030000\t*\r\n",
            "Steps: 33000\tLoss: 81618.84375\tPPL: 7.79562\tbleu: 24.83050\tLR: 0.00030000\t*\r\n",
            "Steps: 34000\tLoss: 80901.36719\tPPL: 7.65616\tbleu: 24.48738\tLR: 0.00030000\t*\r\n",
            "Steps: 35000\tLoss: 81903.55469\tPPL: 7.85167\tbleu: 23.83808\tLR: 0.00030000\t\r\n",
            "Steps: 36000\tLoss: 80545.07031\tPPL: 7.58783\tbleu: 24.64562\tLR: 0.00030000\t*\r\n",
            "Steps: 37000\tLoss: 80361.35938\tPPL: 7.55284\tbleu: 24.38640\tLR: 0.00030000\t*\r\n",
            "Steps: 38000\tLoss: 79592.93750\tPPL: 7.40822\tbleu: 24.61210\tLR: 0.00030000\t*\r\n",
            "Steps: 39000\tLoss: 79011.64844\tPPL: 7.30066\tbleu: 24.20289\tLR: 0.00030000\t*\r\n",
            "Steps: 40000\tLoss: 77740.89062\tPPL: 7.07093\tbleu: 25.25894\tLR: 0.00030000\t*\r\n",
            "Steps: 41000\tLoss: 77226.07031\tPPL: 6.97993\tbleu: 25.37660\tLR: 0.00030000\t*\r\n",
            "Steps: 42000\tLoss: 78205.58594\tPPL: 7.15409\tbleu: 24.39649\tLR: 0.00030000\t\r\n",
            "Steps: 43000\tLoss: 76850.36719\tPPL: 6.91426\tbleu: 25.64481\tLR: 0.00030000\t*\r\n",
            "Steps: 44000\tLoss: 76250.15625\tPPL: 6.81063\tbleu: 25.30811\tLR: 0.00030000\t*\r\n",
            "Steps: 45000\tLoss: 76681.22656\tPPL: 6.88490\tbleu: 25.51775\tLR: 0.00030000\t\r\n",
            "Steps: 46000\tLoss: 75706.21094\tPPL: 6.71805\tbleu: 25.24045\tLR: 0.00030000\t*\r\n",
            "Steps: 47000\tLoss: 75827.08594\tPPL: 6.73852\tbleu: 25.57752\tLR: 0.00030000\t\r\n",
            "Steps: 48000\tLoss: 75461.17188\tPPL: 6.67676\tbleu: 26.18958\tLR: 0.00030000\t*\r\n",
            "Steps: 49000\tLoss: 75122.80469\tPPL: 6.62016\tbleu: 25.94373\tLR: 0.00030000\t*\r\n",
            "Steps: 50000\tLoss: 74897.22656\tPPL: 6.58269\tbleu: 25.49816\tLR: 0.00030000\t*\r\n",
            "Steps: 51000\tLoss: 74098.46094\tPPL: 6.45172\tbleu: 26.47910\tLR: 0.00030000\t*\r\n",
            "Steps: 52000\tLoss: 73931.18750\tPPL: 6.42462\tbleu: 26.67728\tLR: 0.00030000\t*\r\n",
            "Steps: 53000\tLoss: 73860.48438\tPPL: 6.41321\tbleu: 26.10905\tLR: 0.00030000\t*\r\n",
            "Steps: 54000\tLoss: 75211.02344\tPPL: 6.63487\tbleu: 25.34913\tLR: 0.00030000\t\r\n",
            "Steps: 55000\tLoss: 73962.61719\tPPL: 6.42971\tbleu: 26.06067\tLR: 0.00030000\t\r\n",
            "Steps: 56000\tLoss: 73698.60156\tPPL: 6.38714\tbleu: 25.90161\tLR: 0.00030000\t*\r\n",
            "Steps: 57000\tLoss: 73084.50781\tPPL: 6.28921\tbleu: 26.42595\tLR: 0.00030000\t*\r\n",
            "Steps: 58000\tLoss: 73157.67188\tPPL: 6.30080\tbleu: 26.15859\tLR: 0.00030000\t\r\n",
            "Steps: 59000\tLoss: 72459.48438\tPPL: 6.19108\tbleu: 26.79399\tLR: 0.00030000\t*\r\n",
            "Steps: 60000\tLoss: 72793.81250\tPPL: 6.24338\tbleu: 26.22971\tLR: 0.00030000\t\r\n",
            "Steps: 61000\tLoss: 72115.55469\tPPL: 6.13774\tbleu: 27.29105\tLR: 0.00030000\t*\r\n",
            "Steps: 62000\tLoss: 72400.74219\tPPL: 6.18194\tbleu: 26.47586\tLR: 0.00030000\t\r\n",
            "Steps: 63000\tLoss: 72494.17188\tPPL: 6.19649\tbleu: 26.60548\tLR: 0.00030000\t\r\n",
            "Steps: 64000\tLoss: 72124.64062\tPPL: 6.13914\tbleu: 26.88133\tLR: 0.00030000\t\r\n",
            "Steps: 65000\tLoss: 71876.00781\tPPL: 6.10086\tbleu: 27.11661\tLR: 0.00030000\t*\r\n",
            "Steps: 66000\tLoss: 71633.27344\tPPL: 6.06371\tbleu: 27.31313\tLR: 0.00030000\t*\r\n",
            "Steps: 67000\tLoss: 71040.13281\tPPL: 5.97389\tbleu: 26.97828\tLR: 0.00030000\t*\r\n",
            "Steps: 68000\tLoss: 70812.83594\tPPL: 5.93982\tbleu: 27.38987\tLR: 0.00030000\t*\r\n",
            "Steps: 69000\tLoss: 70840.50000\tPPL: 5.94396\tbleu: 26.60801\tLR: 0.00030000\t\r\n",
            "Steps: 70000\tLoss: 69878.07031\tPPL: 5.80175\tbleu: 27.51672\tLR: 0.00030000\t*\r\n",
            "Steps: 71000\tLoss: 70876.35156\tPPL: 5.94932\tbleu: 27.04468\tLR: 0.00030000\t\r\n",
            "Steps: 72000\tLoss: 70263.87500\tPPL: 5.85835\tbleu: 27.62588\tLR: 0.00030000\t\r\n"
          ]
        }
      ],
      "source": [
        "# Output our validation accuracy\n",
        "! cat \"models/${src}-${tgt}-${tag}_transformer/validations.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61MQSSIZ1PJg"
      },
      "outputs": [],
      "source": [
        "# # Test our model\n",
        "# !python3 -m joeynmt test \"models/${tgt}-${src}_transformer/config.yaml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHYmze171PJg",
        "outputId": "02e8387b-6c42-4e44-c04a-2b365308157e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-01-14 12:42:25,970 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
            "2022-01-14 12:42:25,972 - INFO - joeynmt.data - Building vocabulary...\n",
            "2022-01-14 12:42:45,777 - INFO - joeynmt.data - Loading dev data...\n",
            "2022-01-14 12:42:45,799 - INFO - joeynmt.data - Loading test data...\n",
            "2022-01-14 12:42:45,817 - INFO - joeynmt.data - Data loaded.\n",
            "2022-01-14 12:42:45,852 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 18000 (with beam_size)\n",
            "2022-01-14 12:42:49,800 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
            "2022-01-14 12:42:50,938 - INFO - joeynmt.model - Enc-dec model built.\n",
            "2022-01-14 12:42:51,167 - INFO - joeynmt.prediction - Decoding on dev set (data/es-ro-37k/dev.bpe.ro)...\n",
            "2022-01-14 12:44:01,376 - INFO - joeynmt.prediction -  dev bleu[13a]:  28.71 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2022-01-14 12:44:01,383 - INFO - joeynmt.prediction - Translations saved to: data/es-ro-37k/out.dev\n",
            "2022-01-14 12:44:01,383 - INFO - joeynmt.prediction - Decoding on test set (data/es-ro-37k/test.bpe.ro)...\n",
            "2022-01-14 12:45:17,716 - INFO - joeynmt.prediction - test bleu[13a]:  28.80 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2022-01-14 12:45:17,724 - INFO - joeynmt.prediction - Translations saved to: data/es-ro-37k/out.test\n"
          ]
        }
      ],
      "source": [
        "!python3 -m joeynmt test configs/transformer_$src-$tgt-$tag.yaml --output_path data/$src-$tgt-$tag/out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjIyYy-D1PJg"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6HiatOo1PJh",
        "outputId": "90c2d724-155e-4d06-b0de-f9234d4a549d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/andreig/anaconda3/envs/ml/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/home/andreig/anaconda3/envs/ml/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/home/andreig/anaconda3/envs/ml/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative 1-gram: 13.333205538010324\n",
            "Cumulative 2-gram: 5.446775843811686e-153\n",
            "Cumulative 3-gram: 4.5758916676176105e-202\n",
            "Cumulative 4-gram: 1.1008850322906383e-229\n"
          ]
        }
      ],
      "source": [
        "ref_corpus = []\n",
        "result_corpus = []\n",
        "with open(os.path.join(data_folder, 'test.{}'.format(target_language))) as f:\n",
        "    ref_corpus.extend(f.readlines())\n",
        "with open('out.test') as f:\n",
        "    result_corpus.extend(f.readlines())\n",
        "\n",
        "# corpus_bleu_score = corpus_bleu(ref_corpus, result_corpus)\n",
        "# print('BLEU corpus', corpus_bleu_score)\n",
        "\n",
        "# sentence_bleu_score = sentence_bleu(ref_corpus, result_corpus)\n",
        "# print('BLEU sentence', sentence_bleu_score)\n",
        "\n",
        "print('Cumulative 1-gram: {}'.format(corpus_bleu(ref_corpus, result_corpus, weights=(1, 0, 0, 0)) * 100))\n",
        "print('Cumulative 2-gram: {}'.format(corpus_bleu(ref_corpus, result_corpus, weights=(0.5, 0.5, 0, 0)) * 100))\n",
        "print('Cumulative 3-gram: {}'.format(corpus_bleu(ref_corpus, result_corpus, weights=(0.33, 0.33, 0.33, 0)) * 100))\n",
        "print('Cumulative 4-gram: {}'.format(corpus_bleu(ref_corpus, result_corpus, weights=(0.25, 0.25, 0.25, 0.25)) * 100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "joeynmt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}